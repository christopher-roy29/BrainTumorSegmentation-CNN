{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "segmentaion_final - git.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "f7ciD43GWPOY"
      },
      "source": [
        "from keras.engine import Model\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import Dropout, LeakyReLU, Input, Activation, BatchNormalization, Concatenate, multiply, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, UpSampling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.losses import mae\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from keras.utils.vis_utils import plot_model\n",
        " \n",
        "from medpy.io import save as savemha\n",
        "from skimage import color, img_as_float\n",
        "from skimage.exposure import adjust_gamma\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, AveragePooling2D, add\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.initializers import glorot_normal\n",
        "from keras.models import model_from_json\n",
        "import json\n",
        "import matplotlib.image as mpimg\n",
        "    \n",
        "    \n",
        "from __future__ import print_function\n",
        "from glob import glob\n",
        "from skimage import io\n",
        "from errno import EEXIST\n",
        "from os.path import isdir\n",
        "from os import makedirs\n",
        "# import subprocess\n",
        "import progressbar\n",
        "\n",
        "import os\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "from skimage.filters.rank import entropy\n",
        "from skimage.morphology import disk\n",
        "from skimage.io import imsave, imread\n",
        "from skimage.transform import rotate\n",
        "from skimage.color import rgb2gray\n",
        "from os.path import basename\n",
        "import random\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQfLH-T1WPOb"
      },
      "source": [
        "progress = progressbar.ProgressBar(widgets=[progressbar.Bar('*', '[', ']'), progressbar.Percentage(), ' '])\n",
        "np.random.seed(5)  # for reproducibility\n",
        "\n",
        "def mkdir_p(path):\n",
        "    \"\"\"\n",
        "    mkdir -p function, makes folder recursively if required\n",
        "    :param path:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    try:\n",
        "        makedirs(path)\n",
        "    except OSError as exc:  # Python >2.5\n",
        "        if exc.errno == EEXIST and isdir(path):\n",
        "            pass\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "\n",
        "def normalize(slice_el):\n",
        "    \"\"\"\n",
        "    :param slice_el: image to normalize removing 1% from top and bottom\n",
        "     of histogram (intensity removal)\n",
        "    :return: normalized slice\n",
        "    \"\"\"\n",
        "\n",
        "    b = np.percentile(slice_el, 1)\n",
        "    t = np.percentile(slice_el, 99)\n",
        "    slice_el = np.clip(slice_el, b, t)\n",
        "    if np.std(slice_el) == 0:\n",
        "        return slice_el\n",
        "    else:\n",
        "        return (slice_el - np.mean(slice_el)) / np.std(slice_el)\n",
        "\n",
        "\n",
        "class BrainPipeline(object):\n",
        "    \"\"\"\n",
        "    A class for processing brain scans for one patient\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path, n4itk=False, n4itk_apply=False):\n",
        "        \"\"\"\n",
        "        :param path: path to directory of one patient. Contains following mha files:\n",
        "        flair, t1, t1c, t2, ground truth (gt)\n",
        "        :param n4itk:  True to use n4itk normed t1 scans (defaults to True)\n",
        "        :param n4itk_apply: True to apply and save n4itk filter to t1 and t1c scans for given patient.\n",
        "        \"\"\"\n",
        "        self.path = path\n",
        "        self.n4itk = n4itk\n",
        "        self.n4itk_apply = n4itk_apply\n",
        "        self.modes = ['flair', 't1', 't1c', 't2', 'gt']\n",
        "        # slices=[[flair x 155], [t1], [t1c], [t2], [gt]], 155 per modality\n",
        "        self.slices_by_mode, n = self.read_scans()\n",
        "        # [ [slice1 x 5], [slice2 x 5], ..., [slice155 x 5]]\n",
        "        self.slices_by_slice = n\n",
        "        self.normed_slices = self.norm_slices()\n",
        "\n",
        "    def read_scans(self):\n",
        "        \"\"\"\n",
        "        goes into each modality in patient directory and loads individual scans.\n",
        "        transforms scans of same slice into strip of 5 images\n",
        "        \"\"\"\n",
        "        print('Loading scans...')\n",
        "        slices_by_mode = np.zeros((5, 176, 216, 160))\n",
        "        slices_by_slice = np.zeros((176, 5, 216, 160))\n",
        "        flair = glob(self.path + '/*Flair*/*.mha')\n",
        "        t2 = glob(self.path + '/*_T2*/*.mha')\n",
        "        gt = glob(self.path + '/*more*/*.mha')\n",
        "        t1s = glob(self.path + '/**/*T1*.mha')\n",
        "        t1_n4 = glob(self.path + '/*T1*/*_n.mha')\n",
        "        t1 = [scan for scan in t1s if scan not in t1_n4]\n",
        "        scans = [flair[0], t1[0], t1[1], t2[0], gt[0]]  # directories to each image (5 total)\n",
        "        if self.n4itk_apply:\n",
        "            print('-> Applyling bias correction...')\n",
        "            for t1_path in t1:\n",
        "                self.n4itk_norm(t1_path)  # normalize files\n",
        "            scans = [flair[0], t1_n4[0], t1_n4[1], t2[0], gt[0]]\n",
        "        elif self.n4itk:\n",
        "            scans = [flair[0], t1_n4[0], t1_n4[1], t2[0], gt[0]]\n",
        "        for scan_idx in range(5):\n",
        "            # read each image directory, save to self.slices\n",
        "            print(io.imread(scans[scan_idx], plugin='simpleitk').astype(float).shape)\n",
        "            print(scans[scan_idx])\n",
        "            print('*' * 100)\n",
        "            try:\n",
        "                slices_by_mode[scan_idx] = io.imread(scans[scan_idx], plugin='simpleitk').astype(float)\n",
        "            except:\n",
        "                continue\n",
        "        for mode_ix in range(slices_by_mode.shape[0]):  # modes 1 thru 5\n",
        "            for slice_ix in range(slices_by_mode.shape[1]):  # slices 1 thru 155\n",
        "                slices_by_slice[slice_ix][mode_ix] = slices_by_mode[mode_ix][slice_ix]  # reshape by slice\n",
        "        return slices_by_mode, slices_by_slice\n",
        "\n",
        "    def norm_slices(self):\n",
        "        \"\"\"\n",
        "        normalizes each slice in self.slices_by_slice, excluding gt\n",
        "        subtracts mean and div by std dev for each slice\n",
        "        clips top and bottom one percent of pixel intensities\n",
        "        if n4itk == True, will apply n4itk bias correction to T1 and T1c images\n",
        "        \"\"\"\n",
        "        print('Normalizing slices...')\n",
        "        normed_slices = np.zeros((176, 5, 216, 160))\n",
        "        for slice_ix in range(176):\n",
        "            normed_slices[slice_ix][-1] = self.slices_by_slice[slice_ix][-1]\n",
        "            for mode_ix in range(4):\n",
        "                normed_slices[slice_ix][mode_ix] = normalize(self.slices_by_slice[slice_ix][mode_ix])\n",
        "        print ('Done.')\n",
        "        return normed_slices\n",
        "\n",
        "    def save_patient(self, reg_norm_n4, patient_num):\n",
        "        \"\"\"\n",
        "        saves png in Norm_PNG directory for normed, Training_PNG for reg\n",
        "        :param reg_norm_n4:  'reg' for original images, 'norm' normalized images,\n",
        "         'n4' for n4 normalized images\n",
        "        :param patient_num: unique identifier for each patient\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        print('Saving scans for patient {}...'.format(patient_num))\n",
        "        progress.currval = 0\n",
        "        if reg_norm_n4 == 'norm':  # saved normed slices\n",
        "            for slice_ix in progress(range(176)):  # reshape to strip\n",
        "                strip = self.normed_slices[slice_ix].reshape(1080, 160)\n",
        "                if np.max(strip) != 0:  # set values < 1\n",
        "                    strip /= np.max(strip)\n",
        "                if np.min(strip) <= -1:  # set values > -1\n",
        "                    strip /= abs(np.min(strip))\n",
        "                # save as patient_slice.png\n",
        "                try:\n",
        "                    io.imsave('Norm_PNG/{}_{}.png'.format(patient_num, slice_ix), strip)\n",
        "                except:\n",
        "                    mkdir_p('Norm_PNG/')\n",
        "                    io.imsave('Norm_PNG/{}_{}.png'.format(patient_num, slice_ix), strip)\n",
        "        elif reg_norm_n4 == 'reg':\n",
        "            # for slice_ix in progress(range(155)):\n",
        "            for slice_ix in progress(range(176)):\n",
        "                strip = self.slices_by_slice[slice_ix].reshape(1080, 160)\n",
        "                if np.max(strip) != 0:\n",
        "                    strip /= np.max(strip)\n",
        "                try:\n",
        "                    io.imsave('Training_PNG/{}_{}.png'.format(patient_num, slice_ix), strip)\n",
        "                except:\n",
        "                    mkdir_p('Training_PNG/')\n",
        "                    io.imsave('Training_PNG/{}_{}.png'.format(patient_num, slice_ix), strip)\n",
        "        else:\n",
        "            for slice_ix in progress(range(176)):  # reshape to strip\n",
        "                strip = self.normed_slices[slice_ix].reshape(1080, 160)\n",
        "                if np.max(strip) != 0:  # set values < 1\n",
        "                    strip /= np.max(strip)\n",
        "                if np.min(strip) <= -1:  # set values > -1\n",
        "                    strip /= abs(np.min(strip))\n",
        "                # save as patient_slice.png\n",
        "                try:\n",
        "                    io.imsave('n4_PNG/{}_{}.png'.format(patient_num, slice_ix), strip)\n",
        "                except:\n",
        "                    mkdir_p('n4_PNG/')\n",
        "                    io.imsave('n4_PNG/{}_{}.png'.format(patient_num, slice_ix), strip)\n",
        "\n",
        "    def n4itk_norm(self, path, n_dims=3, n_iters='[20,20,10,5]'):\n",
        "        \"\"\"\n",
        "        writes n4itk normalized image to parent_dir under orig_filename_n.mha\n",
        "        :param path: path to mha T1 or T1c file\n",
        "        :param n_dims:  param for n4itk filter\n",
        "        :param n_iters: param for n4itk filter\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        output_fn = path[:-4] + '_n.mha'\n",
        "        # run n4_bias_correction.py path n_dim n_iters output_fn\n",
        "        subprocess.call('python n4_bias_correction.py ' + path + ' ' + str(n_dims) + ' ' + n_iters + ' ' + output_fn,\n",
        "                        shell=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4ybqcCUWPOf"
      },
      "source": [
        "def save_patient_slices(patients, type):\n",
        "    '''\n",
        "    INPUT   (1) list 'patients': paths to any directories of patients to save. for example- glob(\"Training/HGG/**\")\n",
        "            (2) string 'type': options = reg (non-normalized), norm (normalized, but no bias correction), n4 (bias corrected and normalized)\n",
        "    saves strips of patient slices to approriate directory (Training_PNG/, Norm_PNG/ or n4_PNG/) as patient-num_slice-num\n",
        "    '''\n",
        "    for patient_num, path in enumerate(patients):\n",
        "        a = BrainPipeline(path)\n",
        "        a.save_patient(type, patient_num)\n",
        "\n",
        "\n",
        "def save_labels(fns):\n",
        "    '''\n",
        "    INPUT list 'fns': filepaths to all labels\n",
        "    '''\n",
        "    progress.currval = 0\n",
        "    for label_idx in progress(range(len(labels))):\n",
        "        slices = io.imread(labels[label_idx], plugin = 'simpleitk')\n",
        "        for slice_idx in range(len(slices)):\n",
        "            try:\n",
        "                io.imsave('Labels/{}_{}L.png'.format(label_idx, slice_idx), slices[slice_idx])\n",
        "            except:\n",
        "                mkdir_p('Labels/')\n",
        "                io.imsave('Labels/{}_{}L.png'.format(label_idx, slice_idx), slices[slice_idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMMRfmeBWPOj"
      },
      "source": [
        "labels = glob(r'BRATS-2\\Image_Data/HG/**/*more*/**.mha')\n",
        "save_labels(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBgfwttQWPOk"
      },
      "source": [
        "patients = glob(r'BRATS-2\\Image_Data/HG/**')\n",
        "save_patient_slices(patients, 'reg')\n",
        "save_patient_slices(patients, 'norm')\n",
        "save_patient_slices(patients, 'n4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfv2eTqrWPOl"
      },
      "source": [
        "np.random.seed(5)\n",
        "def rotate_patch(patch, angle):\n",
        "    \"\"\"\n",
        "    :param patch: patch of size (4, 33, 33)\n",
        "    :param angle: says how much rotation must be applied\n",
        "    :return: rotate_patch\n",
        "    \"\"\"\n",
        "\n",
        "    return np.array([rotate(patch[0], angle, resize=False),\n",
        "                     rotate(patch[1], angle, resize=False),\n",
        "                     rotate(patch[2], angle, resize=False),\n",
        "                     rotate(patch[3], angle, resize=False)])\n",
        "\n",
        "\n",
        "def get_right_order(filename):\n",
        "    \"\"\"\n",
        "    gives a key_value function for a sorted extraction\n",
        "    :param filename:  path to image\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    last_part = filename.split('/')[len(filename.split('/')) - 1]\n",
        "    number_value = last_part[:-4]\n",
        "    return int(number_value)\n",
        "\n",
        "\n",
        "class PatchLibrary(object):\n",
        "    \"\"\"\n",
        "    class for creating patches and subpatches from training data to use as input for segmentation models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patch_size=(33, 33), train_data='empty', num_samples=1000, augmentation_angle=0):\n",
        "        \"\"\"\n",
        "        :param patch_size: tuple, size (in voxels) of patches to extract. Use (33,33) for sequential model\n",
        "        :param train_data: list of filepaths to all training data saved as pngs. images should have shape (5, 216, 160)\n",
        "        :param num_samples: the number of patches to collect from training data.\n",
        "        :param augmentation_angle: the angle used for flipping patches(producing more datas)\n",
        "        \"\"\"\n",
        "        if 'empty' in train_data:\n",
        "            print(\" insert a path for path extraction\")\n",
        "            exit(1)\n",
        "        self.patch_size = patch_size\n",
        "        if augmentation_angle % 360 != 0:\n",
        "            self.augmentation_multiplier = int(float(360) / float(augmentation_angle))\n",
        "        else:\n",
        "            self.augmentation_multiplier = 1\n",
        "\n",
        "        self.num_samples = num_samples\n",
        "        self.augmentation_angle = augmentation_angle % 360\n",
        "\n",
        "        self.train_data = train_data\n",
        "        self.h = self.patch_size[0]\n",
        "        self.w = self.patch_size[1]\n",
        "\n",
        "    def find_patches(self, class_num, num_patches):\n",
        "        \"\"\"\n",
        "        Helper function for sampling slices with evenly distributed classes\n",
        "        :param class_num: class to sample from choice of {0, 1, 2, 3, 4}.\n",
        "        :param num_patches: number of patches to extract\n",
        "        :return: num_samples patches from class 'class_num' randomly selected.\n",
        "        \"\"\"\n",
        "        h, w = self.patch_size[0], self.patch_size[1]\n",
        "        patches, labels = [], np.full(num_patches * self.augmentation_multiplier, class_num, 'float')\n",
        "        print('Finding patches of class {}...'.format(class_num))\n",
        "\n",
        "        full = False\n",
        "        start_value_extraction = 0\n",
        "        if isdir('patches/') and isdir('patches/class_{}/'.format(class_num)):\n",
        "\n",
        "            # load all patches\n",
        "            # check if quantity is enough to work\n",
        "            path_to_patches = sorted(glob('./patches/class_{}/**.png'.format(class_num)),\n",
        "                                     key=get_right_order)\n",
        "\n",
        "            for path_index in range(len(path_to_patches)):\n",
        "                if path_index < num_patches:\n",
        "                    patch_to_add = rgb2gray(imread(path_to_patches[path_index],\n",
        "                                                   dtype=float)).reshape(4,\n",
        "                                                                         self.patch_size[0],\n",
        "                                                                         self.patch_size[1])\n",
        "\n",
        "                    for el in range(len(patch_to_add)):\n",
        "                        if np.max(patch_to_add[el]) > 1:\n",
        "                            patch_to_add[el] = patch_to_add[el] / np.max(patch_to_add[el])\n",
        "\n",
        "                    patches.append(patch_to_add)\n",
        "                    print('*---> patch {} loaded and added '.format(path_index))\n",
        "                else:\n",
        "                    full = True\n",
        "                    break\n",
        "\n",
        "            if len(path_to_patches) < num_patches:\n",
        "                # change start_value_extraction\n",
        "                start_value_extraction = len(path_to_patches)\n",
        "            else:\n",
        "                full = True\n",
        "        else:\n",
        "            mkdir_p('patches/class_{}'.format(class_num))\n",
        "        if not full:\n",
        "            ct = start_value_extraction\n",
        "            while ct < num_patches:\n",
        "                print('searching for patch {}...'.format(ct))\n",
        "                im_path = random.choice(self.train_data)\n",
        "                fn = basename(im_path)\n",
        "                try:\n",
        "                    label = np.array(\n",
        "                        imread('Labels/' + fn[:-4] + 'L.png'))\n",
        "                except:\n",
        "                    continue\n",
        "                # resample if class_num not in selected slice\n",
        "                unique, counts = np.unique(label, return_counts=True)\n",
        "                labels_unique = dict(zip(unique, counts))\n",
        "                try:\n",
        "                    if labels_unique[class_num] < 10:\n",
        "                        continue\n",
        "                except:\n",
        "                    continue\n",
        "                # select centerpix (p) and patch (p_ix)\n",
        "                img = imread(im_path).reshape(5, 216, 160)[:-1].astype('float')\n",
        "                p = random.choice(np.argwhere(label == class_num))\n",
        "                p_ix = (p[0] - (h // 2), p[0] + ((h + 1) // 2), p[1] - (w // 2), p[1] + ((w + 1) // 2))\n",
        "                patch = np.array([i[p_ix[0]:p_ix[1], p_ix[2]:p_ix[3]] for i in img])\n",
        "\n",
        "                # resample if patch is empty or too close to edge\n",
        "                if patch.shape != (4, h, w) or len(np.argwhere(patch == 0)) > (3 * h * w):\n",
        "                    if class_num == 0 and patch.shape == (4, h, w):\n",
        "                        pass\n",
        "                    else:\n",
        "                        continue\n",
        "\n",
        "                for slice_el in range(len(patch)):\n",
        "                    if np.max(patch[slice_el]) != 0:\n",
        "                        patch[slice_el] /= np.max(patch[slice_el])\n",
        "                imsave('./patches/class_{}/{}.png'.format(class_num,\n",
        "                                                          ct),\n",
        "                       (np.array(patch.reshape((4 * self.patch_size[0], self.patch_size[1])))))\n",
        "                patches.append(patch)\n",
        "                print('*---> patch {} saved and added'.format(ct))\n",
        "                ct += 1\n",
        "\n",
        "\n",
        "        if self.augmentation_angle != 0:\n",
        "            print('_*_*_*_ proceed with data augmentation  for class {} _*_*_*_'.format(class_num))\n",
        "            print()\n",
        "\n",
        "            if isdir('./patches/class_{}/rotations'.format(\n",
        "                    class_num)):\n",
        "                print(\"rotations folder present \")\n",
        "            else:\n",
        "                mkdir_p('./patches/class_{}/rotations'.format(\n",
        "                    class_num))\n",
        "                print(\"rotations folder created\")\n",
        "            for el_index in range(len(patches)):\n",
        "                for j in range(1, self.augmentation_multiplier):\n",
        "                    try:\n",
        "                        patch_rotated = np.array(rgb2gray(imread('./patches/class_{}/'\n",
        "                                                                 'rotations/{}_{}.png'.format(class_num,\n",
        "                                                                                              el_index,\n",
        "                                                                                              self.augmentation_angle * j)),\n",
        "                                                          dtype=float)).reshape(4,\n",
        "                                                                                self.patch_size[0],\n",
        "                                                                                self.patch_size[1])\n",
        "\n",
        "                        for slice_el in range(len(patch_rotated)):\n",
        "                            if np.max(patch_rotated[slice_el]) > 1:\n",
        "                                patch_rotated[slice_el] /= np.max(patch_rotated[slice_el])\n",
        "\n",
        "                        patches.append(patch_rotated)\n",
        "                        print('*---> patch {} loaded and added '\n",
        "                              'with rotation of {} degrees'.format(el_index,\n",
        "                                                                   self.augmentation_angle * j))\n",
        "                    except:\n",
        "\n",
        "                        final_rotated_patch = rotate_patch(np.array(patches[el_index]), self.augmentation_angle * j)\n",
        "                        patches.append(final_rotated_patch)\n",
        "                        imsave('./patches/class_{}/'\n",
        "                               'rotations/{}_{}.png'.format(class_num,\n",
        "                                                            el_index,\n",
        "                                                            self.augmentation_angle * j),\n",
        "                               np.array(final_rotated_patch).reshape(4 * self.patch_size[0], self.patch_size[1]))\n",
        "                        print(('*---> patch {} saved and added '\n",
        "                               'with rotation of {} degrees '.format(el_index,\n",
        "                                                                     self.augmentation_angle * j)))\n",
        "            print('augmentation done \\n')\n",
        "\n",
        "\n",
        "        return np.array(patches), labels\n",
        "\n",
        "\n",
        "    def make_training_patches(self, classes=None):\n",
        "        \"\"\"\n",
        "        Creates datas(X) and labels(y) for training CNN\n",
        "        :param entropy: if True, half of the patches are chosen based on highest entropy area.\n",
        "        defaults to False.\n",
        "        :param classes: list of classes to sample from.\n",
        "         Only change default if entropy is False and balanced_classes is True\n",
        "        :return:\n",
        "        datas : patches (num_samples, 4_chan, h, w)\n",
        "        labels (num_samples,)\n",
        "        \"\"\"\n",
        "        if classes is None:\n",
        "            classes = [0, 1, 2, 3, 4]\n",
        "            per_class = self.num_samples // len(classes)\n",
        "            patches, labels = [], []\n",
        "            progress.currval = 0\n",
        "            for i in progress(range(len(classes))):\n",
        "                p, l = self.find_patches(classes[i], per_class)\n",
        "                patches.append(p)\n",
        "                labels.append(l)\n",
        "            return np.array(patches).reshape(self.num_samples * self.augmentation_multiplier, 4, self.h,\n",
        "                                             self.w), np.array(labels).reshape(\n",
        "                self.num_samples * self.augmentation_multiplier)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbeUL-5WWPOl"
      },
      "source": [
        "train_data = glob(r'n4_PNG/**')\n",
        "patch_extractor = PatchLibrary(train_data=train_data, num_samples=10000,patch_size=(33,33),augmentation_angle = 180)\n",
        "patches, labels = patch_extractor.make_training_patches()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCVCVTXYWPOs"
      },
      "source": [
        "print(patches.shape,labels.shape)\n",
        "io.imshow(patches[666,0,:,:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp76XZ5UWPOt"
      },
      "source": [
        "class Brain_tumor_segmentation_model(object):\n",
        "\n",
        "    \"\"\"\n",
        "    A class for compiling/loading, fitting and saving various models,\n",
        "     viewing segmented images and analyzing results\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_chan=4, loaded_model=False, model_name=None):\n",
        "        \"\"\"\n",
        "        :param model_name: if loaded_model is True load the model name specified\n",
        "        :param n_chan:number of channels being assessed. defaults to 4\n",
        "        :param loaded_model: True if loading a pre-existing model. defaults to False\n",
        "        \"\"\"\n",
        "        self.n_chan = n_chan\n",
        "        self.loaded_model = loaded_model\n",
        "        self.model = None\n",
        "\n",
        "        if not self.loaded_model:\n",
        "            self.model_name = None\n",
        "            self._make_model()\n",
        "            self._compile_model()\n",
        "            print('model for {} ready and compiled, waiting for training'.format(self.model_name))\n",
        "        else:\n",
        "            if model_name is None:\n",
        "                model_to_load = str(raw_input('Which model should I load? '))\n",
        "            else:\n",
        "                model_to_load = model_name\n",
        "            self.model = self.load_model_weights(model_to_load)\n",
        "\n",
        "    def _make_model(self):\n",
        "        dropout_rate = 0.2\n",
        "        \n",
        "#         model_to_make = Sequential()\n",
        "        inp = Input(shape=(4, 33, 33))\n",
        "        model_to_make = Conv2D(64, (3, 3),\n",
        "                                 kernel_initializer=glorot_normal(),\n",
        "                                 bias_initializer='zeros',\n",
        "                                 padding='same',\n",
        "                                 data_format='channels_first',\n",
        "                                 input_shape=(4, 33, 33)\n",
        "                                 )(inp)\n",
        "#         model_to_make = BatchNormalization()(model_to_make)\n",
        "        model_to_make = LeakyReLU(alpha=0.333)(model_to_make)\n",
        "        m1_res = model_to_make              # residual path\n",
        "                         \n",
        "        model_to_make = Conv2D(filters=64,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 padding='same',\n",
        "                                 data_format='channels_first',\n",
        "                                 input_shape=(64, 33, 33))(model_to_make)\n",
        "#         model_to_make = BatchNormalization()(model_to_make)\n",
        "        model_to_make = LeakyReLU(alpha=0.333)(model_to_make)\n",
        "        model_to_make = Conv2D(filters=64,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 padding='same',\n",
        "                                 data_format='channels_first',\n",
        "                                 input_shape=(64, 33, 33))(model_to_make)\n",
        "#             model_to_make = BatchNormalization()(model_to_make)\n",
        "                \n",
        "        model_to_make = add([model_to_make,m1_res])\n",
        "        model_to_make = LeakyReLU(alpha=0.333)(model_to_make)\n",
        "\n",
        "        model_to_make = MaxPool2D(pool_size=(3, 3),\n",
        "                                    strides=(2, 2),\n",
        "                                    data_format='channels_first',\n",
        "                                    input_shape=(64, 33, 33))(model_to_make)\n",
        "\n",
        "        model_to_make = Conv2D(filters=128,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 padding='same',\n",
        "                                 data_format='channels_first',\n",
        "                                 input_shape=(64, 16, 16))(model_to_make)\n",
        "#         model_to_make = BatchNormalization()(model_to_make)\n",
        "\n",
        "        model_to_make = LeakyReLU(alpha=0.333)(model_to_make)\n",
        "        m1_res = model_to_make             # residual path\n",
        "\n",
        "        model_to_make = Conv2D(filters=128,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 padding='same',\n",
        "                                 data_format='channels_first',\n",
        "                                 input_shape=(128, 16, 16))(model_to_make)\n",
        "#         model_to_make = BatchNormalization()(model_to_make)\n",
        "#         model_to_make = LeakyReLU(alpha=0.333)(model_to_make)\n",
        "\n",
        "        model_to_make = Conv2D(filters=128,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 padding='same',\n",
        "                                 data_format='channels_first',\n",
        "                                 input_shape=(128, 16, 16))(model_to_make)\n",
        "#             model_to_make = BatchNormalization()(model_to_make)\n",
        "            \n",
        "        model_to_make = add([model_to_make,m1_res])\n",
        "        model_to_make = LeakyReLU(alpha=0.333)(model_to_make)\n",
        "        \n",
        "        model_to_make = MaxPool2D(pool_size=(3, 3),\n",
        "                                    strides=(2, 2),\n",
        "                                    data_format='channels_first',\n",
        "                                    input_shape=(128, 16, 16))(model_to_make)\n",
        "        \n",
        "        model_to_make = Flatten()(model_to_make)\n",
        "        model_to_make = Dense(units=256, input_dim=6272)(model_to_make)\n",
        "        \n",
        "        model_to_make = LeakyReLU(alpha=0.333)(model_to_make)\n",
        "        \n",
        "        model_to_make = Dropout(dropout_rate)(model_to_make)\n",
        "        \n",
        "        model_to_make = Dense(units=256, input_dim=256)(model_to_make)\n",
        "        \n",
        "        model_to_make = LeakyReLU(alpha=0.333)(model_to_make)\n",
        "        \n",
        "        model_to_make = Dropout(dropout_rate)(model_to_make)\n",
        "        \n",
        "        model_to_make = Dense(units=5,\n",
        "                                input_dim=256)(model_to_make)\n",
        "        \n",
        "        model_to_make = Activation('softmax')(model_to_make)\n",
        "        \n",
        "        self.model = Model(inputs=inp,outputs=model_to_make)\n",
        "        self.model.summary()\n",
        "\n",
        "    def _compile_model(self):\n",
        "        sgd = SGD(lr=3e-3,\n",
        "                  decay=0,\n",
        "                  momentum=0.9,\n",
        "                  nesterov=True)\n",
        "        print(sgd)\n",
        "        self.model.compile(optimizer=sgd,\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "        plot_model(self.model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "    \n",
        "        \n",
        "    @staticmethod\n",
        "    def load_model_weights(model_name):\n",
        "        \"\"\"\n",
        "        :param model_name: filepath to model and weights, not including extension\n",
        "        :return: Model with loaded weights. can fit on model using loaded_model=True in fit_model method\n",
        "        \"\"\"\n",
        "        print('Loading model {}'.format(model_name))\n",
        "        model_to_load = '{}.json'.format(model_name)\n",
        "        weights = '{}.hdf5'.format(model_name)\n",
        "        with open(model_to_load,\"r+\") as f:\n",
        "            m = f.readline()\n",
        "        model_comp = model_from_json(json.loads(m))\n",
        "        model_comp.load_weights(weights)\n",
        "        print('Done.')\n",
        "        return model_comp\n",
        "\n",
        "    def fit_model(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        :param X_train: list of patches to train on in form (n_sample, n_channel, h, w)\n",
        "        :param y_train: list of labels corresponding to X_train patches in form (n_sample,)\n",
        "        :return: Fits specified model\n",
        "        \"\"\"\n",
        "\n",
        "        print(X_train.shape)\n",
        "        print('*' * 100)\n",
        "        print(y_train.shape)\n",
        "        print('*' * 100)\n",
        "        Y_train = np_utils.to_categorical(y_train, 5)\n",
        "\n",
        "        shuffle = list(zip(X_train, Y_train))\n",
        "        np.random.shuffle(shuffle)\n",
        "\n",
        "        X_train = np.array([shuffle[i][0] for i in range(len(shuffle))])\n",
        "        Y_train = np.array([shuffle[i][1] for i in range(len(shuffle))])\n",
        "        EarlyStopping(monitor='val_loss', patience=2, mode='auto')\n",
        "\n",
        "        n_epochs = 20\n",
        "\n",
        "        self.model.fit(X_train, Y_train, epochs=n_epochs, batch_size=128, verbose=1)\n",
        "\n",
        "    def save_model(self, model_name):\n",
        "        \"\"\"\n",
        "        Saves current model as json and weigts as h5df file\n",
        "        :param model_name: name to save model and weigths under, including filepath but not extension\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        model_to_save = '{}.json'.format(model_name)\n",
        "        weights = '{}.hdf5'.format(model_name)\n",
        "        json_string = self.model.to_json()\n",
        "        try:\n",
        "            self.model.save_weights(weights)\n",
        "        except:\n",
        "            mkdir_p(model_name)\n",
        "            self.model.save_weights(weights)\n",
        "\n",
        "        with open(model_to_save, 'w') as f:\n",
        "            json.dump(json_string, f)\n",
        "\n",
        "\n",
        "    def predict_image(self, test_img):\n",
        "        \"\"\"\n",
        "        predicts classes of input image\n",
        "        :param test_img: filepath to image to predict on\n",
        "        :return: segmented result\n",
        "        \"\"\"\n",
        "        imgs = mpimg.imread(test_img).astype('float')\n",
        "        imgs = rgb2gray(imgs).reshape(5, 216, 160)\n",
        "\n",
        "        plist = []\n",
        "\n",
        "        # create patches_to_predict from an entire slice\n",
        "        for img in imgs[:-1]:\n",
        "            if np.max(img) != 0:\n",
        "                img /= np.max(img)\n",
        "            p = extract_patches_2d(img, (33, 33))\n",
        "            plist.append(p)\n",
        "        patches_to_predict = np.array(\n",
        "            list(zip(np.array(plist[0]), np.array(plist[1]), np.array(plist[2]), np.array(plist[3]))))\n",
        "        # predict classes of each pixel based on model\n",
        "        full_pred = self.model.predict(patches_to_predict)\n",
        "        full_pred = np.argmax(full_pred,axis=1)\n",
        "#         print(full_pred.shape)\n",
        "        try:\n",
        "                mkdir_p(\"./labels/\")\n",
        "                io.imsave(\"./labels/\" + test_img[-5:], imgs[-1])\n",
        "        except:\n",
        "                io.imsave(\"./labels/\" + test_img[-5:], imgs[-1])\n",
        "        fp1 = full_pred.reshape(184, 128)\n",
        "        return fp1\n",
        "\n",
        "    def save_segmented_image(self, index, test_img, save=False):\n",
        "        \"\"\"\n",
        "        Creates an image of original brain with segmentation overlay\n",
        "        :param index: index of image to save\n",
        "        :param test_img: filepath to test image for segmentation, including file extension\n",
        "        :param save: If true, shows output image. (defaults to False)\n",
        "        :return: if show is True, shows image of segmentation results\n",
        "                 if show is false, returns segmented image.\n",
        "        \"\"\"\n",
        "\n",
        "        segmentation = self.predict_image(test_img)\n",
        "\n",
        "        img_mask = np.pad(segmentation, (16, 16), mode='edge')\n",
        "        ones = np.argwhere(img_mask == 1)\n",
        "        twos = np.argwhere(img_mask == 2)\n",
        "        threes = np.argwhere(img_mask == 3)\n",
        "        fours = np.argwhere(img_mask == 4)\n",
        "\n",
        "        test_im = mpimg.imread(test_img).astype('float')\n",
        "        test_back = rgb2gray(test_im).reshape(5, 216, 160)[-2]\n",
        "        gray_img = img_as_float(test_back)\n",
        "\n",
        "        # adjust gamma of image\n",
        "        image = adjust_gamma(color.gray2rgb(gray_img), 0.65)\n",
        "        sliced_image = image.copy()\n",
        "        red_multiplier = [1, 0.2, 0.2]\n",
        "        yellow_multiplier = [1, 1, 0.25]\n",
        "        green_multiplier = [0.35, 0.75, 0.25]\n",
        "        blue_multiplier = [0, 0.25, 0.9]\n",
        "\n",
        "        # change colors of segmented classes\n",
        "        for i in range(len(ones)):\n",
        "            sliced_image[ones[i][0]][ones[i][1]] = red_multiplier\n",
        "        for i in range(len(twos)):\n",
        "            sliced_image[twos[i][0]][twos[i][1]] = green_multiplier\n",
        "        for i in range(len(threes)):\n",
        "            sliced_image[threes[i][0]][threes[i][1]] = blue_multiplier\n",
        "        for i in range(len(fours)):\n",
        "            sliced_image[fours[i][0]][fours[i][1]] = yellow_multiplier\n",
        "        \n",
        "        if save:\n",
        "\n",
        "            try:\n",
        "                mkdir_p('./results/')\n",
        "                io.imsave('./results/result' + '_' + str(index) + '.png', sliced_image)\n",
        "                savemha(img_mask,'./results/result' + '_' + str(index) + '.mha')\n",
        "            except:\n",
        "                io.imsave('./results/result' + '_' + str(index) + '.png', sliced_image)\n",
        "                savemha(img_mask,'./results/result' + '_' + str(index) + '.mha')\n",
        "        else:\n",
        "            return sliced_image\n",
        "    \n",
        "    def get_dice_coef(self, test_img, label):\n",
        "        '''\n",
        "        Calculate dice coefficient for total slice, tumor-associated slice, advancing tumor and core tumor\n",
        "        INPUT   (1) str 'test_img': filepath to slice to predict on\n",
        "                (2) str 'label': filepath to ground truth label for test_img\n",
        "        '''\n",
        "        label = \"./labels/\" + label[-5:]\n",
        "        segmentation = self.predict_image(test_img)\n",
        "        seg_full = np.pad(segmentation, (16,16), mode='edge')\n",
        "        gt = io.imread(label).astype('int')\n",
        "        gt = np.divide(gt,np.max(gt))\n",
        "        gt = np.round(gt * 4).astype('int')\n",
        "        # dice coef of total image\n",
        "        total = (len(np.argwhere(seg_full == gt)) * 2.) / (2 * 216 * 160)\n",
        "\n",
        "        def unique_rows(a):\n",
        "            '''\n",
        "            helper function to get unique rows from 2D numpy array\n",
        "            '''\n",
        "            a = np.ascontiguousarray(a)\n",
        "            unique_a = np.unique(a.view([('', a.dtype)]*a.shape[1]))\n",
        "            return unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))\n",
        "\n",
        "        # dice coef advancing tumor\n",
        "        adv_gt = np.argwhere(gt == 4)\n",
        "#         print(np.unique(gt))\n",
        "        gt_a, seg_a = [], [] # classification of\n",
        "        for i in adv_gt:\n",
        "            gt_a.append(gt[i[0]][i[1]])\n",
        "            seg_a.append(seg_full[i[0]][i[1]])\n",
        "        gta = np.array(gt_a)\n",
        "        sega = np.array(seg_a)\n",
        "        adv = float(len(np.argwhere(gta == sega))) / len(adv_gt)\n",
        "\n",
        "        # dice coef core tumor\n",
        "        noadv_gt = np.argwhere(gt == 3)\n",
        "        necrosis_gt = np.argwhere(gt == 1)\n",
        "        live_tumor_gt = np.append(adv_gt, noadv_gt, axis = 0)\n",
        "        core_gt = np.append(live_tumor_gt, necrosis_gt, axis = 0)\n",
        "        gt_core, seg_core = [],[]\n",
        "        for i in core_gt:\n",
        "            gt_core.append(gt[i[0]][i[1]])\n",
        "            seg_core.append(seg_full[i[0]][i[1]])\n",
        "        gtcore, segcore = np.array(gt_core), np.array(seg_core)\n",
        "        core = len(np.argwhere(gtcore == segcore)) / float(len(core_gt))\n",
        "\n",
        "        print ('Region_______________________| Dice Coefficient')\n",
        "        print ('Total Slice__________________| {0:.2f}'.format(total))\n",
        "        print ('Advancing Tumor______________| {0:.2f}'.format(adv))\n",
        "        print ('Core Tumor___________________| {0:.2f}'.format(core))\n",
        "        print (' ')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI7LzwSFWPOt"
      },
      "source": [
        "model = Brain_tumor_segmentation_model()\n",
        "model.fit_model(patches, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSfpUy7bWPOu"
      },
      "source": [
        "#saving the trained model and weights\n",
        "model.save_model('residual_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZPWM3mOWPOu"
      },
      "source": [
        "#segments the given test images in folder and saves the result\n",
        "tests = glob(r'experiment/**')\n",
        "segmented_images = []\n",
        "for index, slice_img in enumerate(tests):\n",
        "    segmented_images.append(model.save_segmented_image(index, test_img=slice_img, save=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnb_mStLWPOu"
      },
      "source": [
        "#Cell to find the DICE similarity coefficient between predicted and Ground Truth image\n",
        "for slice_img in tests:\n",
        "    print('-----Dice Coefficient for slice {} -----'.format(slice_img[84:]))\n",
        "    model.get_dice_coef(test_img = slice_img, label = slice_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngpp7v2RWPOu"
      },
      "source": [
        "#Cell to segment all 155 slices of a particular patient\n",
        "tests = sorted(glob(r'experiment\\all slices/**'))\n",
        "segmented_images = []\n",
        "for index, slice_img in enumerate(tests):\n",
        "    segmented_images.append(model.save_segmented_image(index, test_img=slice_img, save=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVNxe_RbWPOv",
        "outputId": "06ee95f3-95c7-4d09-a8dd-b6dfa0542fe8"
      },
      "source": [
        "# Cell to colour the Ground Truth in training and save it!\n",
        "tests1 = glob(r'experiment/**')\n",
        "for index, slice_img in enumerate(tests1):\n",
        "    imgs = mpimg.imread(slice_img).astype('float')\n",
        "    imgs = rgb2gray(imgs).reshape(5, 216, 160)\n",
        "    img_mask = imgs[-1]\n",
        "    img_mask = np.divide(img_mask,np.max(img_mask))\n",
        "    img_mask = np.round(img_mask * 4).astype('int')\n",
        "    ones = np.argwhere(img_mask == 1)\n",
        "    twos = np.argwhere(img_mask == 2)\n",
        "    threes = np.argwhere(img_mask == 3)\n",
        "    fours = np.argwhere(img_mask == 4)\n",
        "\n",
        "    test_back = imgs[-2]\n",
        "    # overlay = mark_boundaries(test_back, img_mask)\n",
        "    gray_img = img_as_float(test_back)\n",
        "\n",
        "    # adjust gamma of image\n",
        "    image = adjust_gamma(color.gray2rgb(gray_img), 0.65)\n",
        "    sliced_image = image.copy()\n",
        "    red_multiplier = [1, 0.2, 0.2]\n",
        "    yellow_multiplier = [1, 1, 0.25]\n",
        "    green_multiplier = [0.35, 0.75, 0.25]\n",
        "    blue_multiplier = [0, 0.25, 0.9]\n",
        "\n",
        "    # change colors of segmented classes\n",
        "    for i in range(len(ones)):\n",
        "        sliced_image[ones[i][0]][ones[i][1]] = red_multiplier\n",
        "    for i in range(len(twos)):\n",
        "        sliced_image[twos[i][0]][twos[i][1]] = green_multiplier\n",
        "    for i in range(len(threes)):\n",
        "        sliced_image[threes[i][0]][threes[i][1]] = blue_multiplier\n",
        "    for i in range(len(fours)):\n",
        "        sliced_image[fours[i][0]][fours[i][1]] = yellow_multiplier\n",
        "\n",
        "    try:\n",
        "        mkdir_p('./results/')\n",
        "        io.imsave('./results/resultGT' + '_' + str(index) + '.png', sliced_image)\n",
        "    except:\n",
        "        io.imsave('./results/resultGT' + '_' + str(index) + '.png', sliced_image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
            "  .format(dtypeobj_in, dtypeobj_out))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1svmn7QgWPOv"
      },
      "source": [
        "# run this cell to load the saved model and segment the images present in experiment folder\n",
        "model1 = Brain_tumor_segmentation_model(loaded_model= True,model_name='residual_model')\n",
        "location = glob(r'.\\experiment/**')\n",
        "for index, slice_img in enumerate(location):\n",
        "    model1.save_segmented_image(index, test_img=slice_img, save=True)\n",
        "    model1.get_dice_coef(test_img = slice_img, label = slice_img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}